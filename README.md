# ğŸ§  AI Task Automation Sandbox

A lightweight, local task execution engine using the **Mistral LLM** via `Ollama`.

## âœ… Features
- ğŸ§  Free, local large language model (Mistral 7B via Ollama)
- ğŸ“¥ Reads prompt tasks from `tasks.json`
- ğŸ› ï¸ Routes prompts to appropriate logic (e.g. translation, summarization)
- ğŸš€ Executes via Mistral with no OpenAI dependency

## ğŸ“‚ File Structure
AI-task-automation-sandbox/
â”œâ”€â”€ main.py # CLI runner
â”œâ”€â”€ engine/
â”‚ â”œâ”€â”€ local_llm.py # Local LLM runner using Ollama
â”‚ â”œâ”€â”€ router.py # Task type router
â”‚ â””â”€â”€ executor.py # Routes prompt + formats query
â”œâ”€â”€ data/
â”‚ â””â”€â”€ tasks.json # Prompt input
â”œâ”€â”€ requirements.txt # Dependencies

## â–¶ï¸ How to Run
1. **Start the Mistral model:**
ollama run mistral
2. **In another terminal:**
python main.py
3. ğŸ” Model processes 10 prompts from `data/tasks.json`
4. pip install -r requirements.txt
